"""
tiga.py — TIGA Hunt CLI entrypoint.

Subcommands:
  init      Generate default config.yaml in work_dir
  discover  List files that would be indexed (dry run)
  extract   Test text extraction on a single file
  embed     Test Ollama embedding on a query string
  index     Index archive files (incremental by default)
  rebuild   Force full re-index
  query     Search the archive from terminal
  status    Show index stats
  eval      Run search quality evaluation
  serve     Start the FastAPI LAN server
  einstein  Phase 2 (stub)
"""

from __future__ import annotations

import argparse
import json
import sys
import time


# ---------------------------------------------------------------------------
# Default config template (written by `init`)
# ---------------------------------------------------------------------------

_CONFIG_TEMPLATE = """\
# TIGA Hunt — Configuration
# Generated by: python tiga.py init
# Edit index_roots to point at your archive directories.

work_dir: ./tiga_work

# Directories to scan and index
index_roots:
  - "Z:/186 - Tianmu"
  - "Z:/242 - World Expo Pavilion"
  - "Z:/232 - SIT Campus"

include_globs:
  - '**/*'
exclude_globs:
  - '**/.git/**'
  - '**/~$*'
  - '**/*.tmp'
  - '**/node_modules/**'
  - '**/__pycache__/**'

max_file_mb: 2048

lane_rules:
  text_extractable_exts: [.pdf, .docx, .pptx, .txt, .md, .doc]
  metadata_only_exts: [.dwg, .rvt, .ifc, .skp, .3dm, .jpg, .jpeg, .png, .mp4, .mov, .avi]

ollama:
  base_url: http://localhost:11434
  embed_model: nomic-embed-text
  chat_model: mistral
  timeout_seconds: 30
  gpu_layers: -1
  num_ctx: 4096
  embed_batch_size: 32
  embed_batch_sleep_s: 0.1

server:
  host: 0.0.0.0
  port: 7860
  workers: 2

ui:
  port: 8501
  title: TIGA Hunt
  max_session_history: 20

project_inference:
  enable: true
  confidence_threshold_unknown: 0.5
  patterns:
    - name: year-code
      regex: '^(\\d{3,4})[-_ ]'
      weight: 0.8
  keyword_boosts:
    - {keyword: brief,      weight: 0.2}
    - {keyword: tender,     weight: 0.2}
    - {keyword: submission, weight: 0.2}
    - {keyword: SD,         weight: 0.1}
    - {keyword: DD,         weight: 0.1}

typology_inference:
  confidence_threshold_unknown: 0.5
  keyword_map:
    healthcare:   [hospital, clinic, healthcare, medical]
    education:    [school, campus, university, polytechnic, sit]
    sports:       [sports, stadium, arena, aquatic]
    residential:  [residential, housing, hdb, apartment]
    commercial:   [office, commercial, retail, hotel]
    cultural:     [museum, gallery, library, theatre, pavilion, expo]

retrieval:
  top_k_default: 5
  hybrid_weight_bm25: 0.4
  hybrid_weight_vector: 0.6

ocr:
  enabled: false
  tesseract_cmd: tesseract

einstein:
  enable: false
  base_model: mistral
  adapter_path: ./tiga_work/einstein/adapter
"""


# ---------------------------------------------------------------------------
# Eval fixture template
# ---------------------------------------------------------------------------

_FIXTURE_TEMPLATE = """\
# TIGA Hunt — eval fixture
# Edit these entries to match your POC archive.
# Run: python tiga.py eval
#
# expected_paths: suffix-match against indexed file_path (partial paths OK)
# expected_project: optional label (not used in scoring yet)

- query: "hospital brief 2019"
  expected_paths:
    - 2019_HOSP/brief.pdf
  expected_project: "2019_HOSP"

- query: "school competition submission"
  expected_paths:
    - Competitions/submission.pdf

- query: "site analysis residential"
  expected_paths:
    - site_analysis.pdf
"""


# ---------------------------------------------------------------------------
# Commands
# ---------------------------------------------------------------------------

def cmd_init(args: argparse.Namespace) -> None:
    """Generate default config.yaml and eval fixture in work_dir."""
    import os
    from pathlib import Path

    work_dir_env = os.environ.get("TIGA_WORK_DIR")
    work_dir = Path(work_dir_env).resolve() if work_dir_env else (
        Path(__file__).resolve().parent / "tiga_work"
    )
    config_file = work_dir / "config.yaml"

    work_dir.mkdir(parents=True, exist_ok=True)

    if config_file.exists() and not args.force:
        print(f"Config already exists: {config_file}")
        print("Use --force to overwrite.")
        return

    config_file.write_text(_CONFIG_TEMPLATE, encoding="utf-8")
    print(f"Created: {config_file}")

    # Eval fixture (always written; non-destructive)
    fixtures_dir = work_dir / "fixtures"
    fixtures_dir.mkdir(parents=True, exist_ok=True)
    fixture_file = fixtures_dir / "eval_queries.yaml"
    if not fixture_file.exists():
        fixture_file.write_text(_FIXTURE_TEMPLATE, encoding="utf-8")
        print(f"Created: {fixture_file}")

    print("\nNext steps:")
    print("  1. Edit tiga_work/config.yaml — set your index_roots")
    print("  2. Edit tiga_work/fixtures/eval_queries.yaml — add test queries")
    print("  3. Install Ollama from https://ollama.com")
    print("  4. Run: ollama pull nomic-embed-text && ollama pull mistral")
    print("  5. Run: python tiga.py index")
    print("  6. Run: python tiga.py serve   (in one terminal)")
    print("          python tiga.py ui      (in another)")


def cmd_discover(args: argparse.Namespace) -> None:
    from collections import Counter
    from core.discover import discover

    print("Scanning index_roots…")
    files = discover()

    ext_counts: Counter[str] = Counter(f.suffix.lower() for f in files)
    print(f"\nFound {len(files)} files\n")
    print(f"{'Extension':<12} {'Count':>6}")
    print("-" * 20)
    for ext, count in sorted(ext_counts.items(), key=lambda x: -x[1]):
        print(f"{ext:<12} {count:>6}")

    if args.list:
        print("\nFiles:")
        for f in files:
            print(f"  {f}")


def cmd_extract(args: argparse.Namespace) -> None:
    from pathlib import Path
    from core.extract import extract

    path = Path(args.file)
    if not path.exists():
        print(f"File not found: {path}", file=sys.stderr)
        sys.exit(1)

    print(f"Extracting: {path}")
    text, surrogate = extract(path)
    print(f"\n--- Surrogate ---\n{surrogate}")
    if text:
        preview = text[:1000]
        print(f"\n--- Text preview (first 1000 chars) ---\n{preview}")
        if len(text) > 1000:
            print(f"… [{len(text) - 1000} more chars]")
    else:
        print("\n[No text extracted — metadata-only file]")


def cmd_embed(args: argparse.Namespace) -> None:
    from config import ollama_available, cfg
    from core.vectors import embed_texts

    query = " ".join(args.query)
    print(f"Query: {query!r}")

    if not ollama_available(cfg.ollama_base_url):
        print("Ollama is not reachable. Is it running?", file=sys.stderr)
        sys.exit(1)

    t0 = time.perf_counter()
    embeddings = embed_texts([query])
    elapsed = round((time.perf_counter() - t0) * 1000, 1)
    vec = embeddings[0]
    print(f"Embedding dimensions: {len(vec)}")
    print(f"First 8 values: {[round(v, 4) for v in vec[:8]]}")
    print(f"Elapsed: {elapsed} ms")


def cmd_index(args: argparse.Namespace) -> None:
    from config import cfg
    from core.db import get_connection
    from core.index import run_full_pipeline

    cfg.ensure_dirs()
    conn = get_connection(cfg.get_db_path())
    print("Starting incremental index (discover → extract → embed → FTS)…")
    t0 = time.perf_counter()
    try:
        stats = run_full_pipeline(conn, cfg_obj=cfg)
    finally:
        conn.close()
    elapsed = round(time.perf_counter() - t0, 1)
    print(
        f"\nDone in {elapsed}s — "
        f"discovered: {stats.get('discovered', 0)} new files | "
        f"extracted: {stats.get('files_extracted', 0)} files "
        f"({stats.get('chunks_new', 0)} chunks) | "
        f"embedded: {stats.get('files_embedded', 0)} files, "
        f"{stats.get('chunks_embedded', 0)} chunks "
        f"({stats.get('chunks_skipped', 0)} skipped) | "
        f"indexed: {stats.get('files_indexed', 0)} files"
    )


def cmd_rebuild(args: argparse.Namespace) -> None:
    from config import cfg
    from core.db import get_connection
    from core.index import run_rebuild

    cfg.ensure_dirs()
    conn = get_connection(cfg.get_db_path())
    print("Rebuilding index from scratch (FTS drop + LanceDB reset)…")
    t0 = time.perf_counter()
    try:
        stats = run_rebuild(conn, cfg_obj=cfg)
    finally:
        conn.close()
    elapsed = round(time.perf_counter() - t0, 1)
    print(
        f"\nRebuild complete in {elapsed}s — "
        f"embedded: {stats.get('files_embedded', 0)} files, "
        f"{stats.get('chunks_embedded', 0)} chunks | "
        f"indexed: {stats.get('files_indexed', 0)} files"
    )


def cmd_query(args: argparse.Namespace) -> None:
    from core.query import search
    from core.compose import compose
    from config import cfg

    query = " ".join(args.query)
    if not query:
        print("Usage: tiga.py query <your question>")
        sys.exit(1)

    print(f"\nSearching: {query!r}\n")
    t0 = time.perf_counter()
    results = search(query, top_k=args.top_k)
    answer = compose(query, results)
    elapsed = round((time.perf_counter() - t0) * 1000, 1)

    print(answer)
    print(f"\n--- {elapsed} ms | {len(results)} results ---")
    for i, r in enumerate(results, 1):
        print(
            f"  [{i}] {r.get('file_name', r.get('rel_path', ''))}  "
            f"project={r.get('project_id', r.get('project', 'Unknown'))}  "
            f"typology={r.get('typology', 'Unknown')}  "
            f"score={r.get('final_score', r.get('combined_score', 0.0)):.3f}  "
            f"cite={r.get('citation', '')}"
        )


def cmd_status(_args: argparse.Namespace) -> None:
    from config import cfg
    from core.db import get_connection, get_stats

    conn = get_connection(cfg.get_db_path())
    stats = get_stats(conn)
    conn.close()
    print(json.dumps(stats, indent=2))
    print(f"index_roots: {[str(d) for d in cfg.index_roots]}")


def cmd_eval(args: argparse.Namespace) -> None:
    from core.eval import run_eval

    queries = args.queries if args.queries else None
    code = run_eval(queries=queries, top_k=args.top_k)
    sys.exit(code)


def cmd_serve(_args: argparse.Namespace) -> None:
    from config import cfg
    import uvicorn

    print(f"Starting TIGA Hunt server at http://{cfg.server_host}:{cfg.server_port}")
    uvicorn.run(
        "server:app",
        host=cfg.server_host,
        port=cfg.server_port,
        workers=cfg.server_workers,
        reload=False,
    )


def cmd_ui(_args: argparse.Namespace) -> None:
    import socket
    import subprocess
    from config import cfg

    ui_port = cfg.server_port + 1
    try:
        local_ip = socket.gethostbyname(socket.gethostname())
    except Exception:
        local_ip = "127.0.0.1"
    print(f"TIGA UI: http://{local_ip}:{ui_port}")
    subprocess.run(
        [sys.executable, "-m", "streamlit", "run", "app.py",
         "--server.port", str(ui_port),
         "--server.address", "0.0.0.0",
         "--server.headless", "true"],
        check=True,
    )


def cmd_einstein(_args: argparse.Namespace) -> None:
    from config import cfg

    if not cfg.einstein_enable:
        print("Einstein is disabled. Set einstein.enable: true in config.yaml.")
        print("(Phase 2 — not yet implemented)")
        return
    print("Einstein: Phase 2 not yet implemented.")


def cmd_health(_args: argparse.Namespace) -> None:
    from config import cfg, ollama_available
    from core.db import get_connection

    print(f"Ollama ({cfg.ollama_base_url}) … ", end="", flush=True)
    print("OK" if ollama_available(cfg.ollama_base_url) else "UNREACHABLE")

    print("SQLite DB … ", end="", flush=True)
    try:
        conn = get_connection(cfg.get_db_path())
        conn.execute("SELECT 1")
        conn.close()
        print("OK")
    except Exception as e:
        print(f"FAIL ({e})")

    print(f"Chat model:  {cfg.chat_model}")
    print(f"Embed model: {cfg.embed_model}")


# ---------------------------------------------------------------------------
# Argument parser
# ---------------------------------------------------------------------------

def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="tiga",
        description="TIGA Hunt — archive search CLI",
    )
    sub = parser.add_subparsers(dest="command", required=True)

    # init
    p_init = sub.add_parser("init", help="Create default config.yaml")
    p_init.add_argument("--force", action="store_true", help="Overwrite existing config")

    # discover
    p_disc = sub.add_parser("discover", help="List files that would be indexed")
    p_disc.add_argument("--list", action="store_true", help="Print all file paths")

    # extract
    p_ext = sub.add_parser("extract", help="Test extraction on a file")
    p_ext.add_argument("file", help="Path to file")

    # embed
    p_emb = sub.add_parser("embed", help="Test Ollama embedding")
    p_emb.add_argument("query", nargs="+", help="Text to embed")

    # index
    sub.add_parser("index", help="Incremental index of archive")

    # rebuild
    sub.add_parser("rebuild", help="Force full re-index")

    # query
    p_q = sub.add_parser("query", help="Search the archive")
    p_q.add_argument("query", nargs="+", help="Search query")
    p_q.add_argument("--top-k", type=int, default=5)

    # status
    sub.add_parser("status", help="Show index statistics")

    # eval
    p_ev = sub.add_parser("eval", help="Run search quality evaluation")
    p_ev.add_argument("--queries", nargs="*", help="Custom test queries")
    p_ev.add_argument("--top-k", type=int, default=5)

    # serve
    sub.add_parser("serve", help="Start FastAPI LAN server")

    # ui
    sub.add_parser("ui", help="Start Streamlit UI")

    # health
    sub.add_parser("health", help="Check Ollama + DB connectivity")

    # einstein
    sub.add_parser("einstein", help="Phase 2 (stub)")

    return parser


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main() -> None:
    parser = build_parser()
    args = parser.parse_args()

    dispatch = {
        "init":     cmd_init,
        "discover": cmd_discover,
        "extract":  cmd_extract,
        "embed":    cmd_embed,
        "index":    cmd_index,
        "rebuild":  cmd_rebuild,
        "query":    cmd_query,
        "status":   cmd_status,
        "eval":     cmd_eval,
        "serve":    cmd_serve,
        "ui":       cmd_ui,
        "health":   cmd_health,
        "einstein": cmd_einstein,
    }
    dispatch[args.command](args)


if __name__ == "__main__":
    main()
